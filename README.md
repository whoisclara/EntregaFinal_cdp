##Proyecto Final â€“ Ciencia de Datos en ProducciÃ³n

Este repositorio contiene el desarrollo completo del proyecto final del curso Ciencia de Datos en ProducciÃ³n, el cual implementa una soluciÃ³n de Machine Learning, integrando procesamiento de datos, modelado, evaluaciÃ³n y despliegue automatizado con Jenkins y Docker.

EntregaFinal_cdp/
â”‚
â”œâ”€â”€ models/                  # Modelos entrenados (.pkl)
â”‚
â”œâ”€â”€ pyops/                   # Scripts de operaciones (Jenkins)
â”‚   â”œâ”€â”€ jenkins_home/        # Directorio persistente de Jenkins
â”‚   â””â”€â”€ check_structure.py   # VerificaciÃ³n de estructura del proyecto
â”‚
â”œâ”€â”€ src/                     # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ static/              # Archivos estÃ¡ticos (web)
â”‚   â”œâ”€â”€ templates/           # Plantillas HTML (si aplica)
â”‚   â”œâ”€â”€ Carga_datos.py       # ConexiÃ³n y carga de datos desde BigQuery
â”‚   â”œâ”€â”€ ft_engineering.py    # Feature engineering y escalado
â”‚   â”œâ”€â”€ heuristic_model.py   # Modelo base heurÃ­stico
â”‚   â”œâ”€â”€ model_training.py    # Entrenamiento de modelos ML
â”‚   â”œâ”€â”€ model_evaluation.py  # EvaluaciÃ³n de performance
â”‚   â”œâ”€â”€ model_deploy.py      # Despliegue con FastAPI / Vertex / Flask
â”‚   â””â”€â”€ EDA.ipynb            # ExploraciÃ³n de datos
â”‚
â”œâ”€â”€ docker-compose.yml       # OrquestaciÃ³n de servicios (Jenkins + app)
â”œâ”€â”€ Dockerfile               # Imagen base del proyecto
â”œâ”€â”€ requirements.txt         # Dependencias de Python
â”œâ”€â”€ .env                     # Variables de entorno (no subir con claves)
â”œâ”€â”€ set_up.bat               # Script de inicializaciÃ³n local
â””â”€â”€ README.md                # Este documento

##âš™ï¸ TecnologÃ­as utilizadas

| Componente                        | DescripciÃ³n                          |
| --------------------------------- | ------------------------------------ |
| **Python 3.10+**                  | Lenguaje principal                   |
| **scikit-learn / pandas / numpy** | Procesamiento, modelado y evaluaciÃ³n |
| **Google BigQuery**               | Fuente de datos en la nube           |
| **FastAPI / Flask**               | Interfaz de despliegue del modelo    |
| **Jenkins**                       | AutomatizaciÃ³n CI/CD                 |
| **Docker / Docker Compose**       | ContenerizaciÃ³n y orquestaciÃ³n       |
| **Vertex AI (opcional)**          | Entrenamiento o evaluaciÃ³n en GCP    |


ğŸš€ Flujo de trabajo

1. Carga y limpieza de datos
    - Carga_datos.py obtiene datos desde BigQuery.
    - Se realiza imputaciÃ³n, normalizaciÃ³n y codificaciÃ³n en ft_engineering.py.
2. Entrenamiento y selecciÃ³n de modelos
    - model_training.py entrena mÃºltiples algoritmos (Logistic Regression, RandomForest, etc.)
    - Se aplica cross-validation y selecciÃ³n del mejor modelo segÃºn mÃ©tricas.

3. EvaluaciÃ³n y mÃ©tricas
    - model_evaluation.py genera reportes de desempeÃ±o (accuracy, ROC-AUC, etc.).

4. Despliegue del modelo
    - model_deploy.py expone el modelo mediante API REST (FastAPI/Flask).
    - Se integra con Jenkins para automatizar builds y pruebas.

5.AutomatizaciÃ³n CI/CD
    - Jenkinsfile y docker-compose.yml coordinan las etapas del pipeline:
        - Build de imagen
        - Test de estructura
        - Entrenamiento / despliegue automatizado

ğŸ§  Autoras:
- Clara Otalvaro 
- Ada Mattos